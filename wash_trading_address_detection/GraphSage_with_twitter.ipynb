{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import GraphConv\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.exceptions import UndefinedMetricWarning, ConvergenceWarning\n",
    "import warnings\n",
    "import copy\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import SAGEConv\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from torch.optim import Adam\n",
    "import random\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load G_train_dgl_with_twitter_features.gpickle, G_val_dgl_with_twitter_features.gpickle, G_test_dgl_with_twitter_features.gpickle\n",
    "with open('G_train_dgl_twitter.gpickle', 'rb') as f:\n",
    "    G_train_dgl_twitter = pkl.load(f)\n",
    "    \n",
    "with open('G_val_dgl_twitter.gpickle', 'rb') as f:\n",
    "    G_val_dgl_twitter = pkl.load(f)\n",
    "    \n",
    "with open('G_test_dgl_twitter.gpickle', 'rb') as f:\n",
    "    G_test_dgl_twitter = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes, dropout_rate=0.1):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, aggregator_type='mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, aggregator_type='mean')  # Added one more layer\n",
    "        self.conv3 = SAGEConv(h_feats, num_classes, aggregator_type='mean')\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Dropout layer\n",
    "        self.batchnorm = nn.BatchNorm1d(h_feats)  # Batch Normalization layer\n",
    "\n",
    "    def forward(self, graph, x):\n",
    "        h = self.conv1(graph, x)\n",
    "        h = F.relu(h)\n",
    "        h = self.dropout(h)  # Apply dropout\n",
    "        h = self.batchnorm(h)  # Apply batch normalization\n",
    "        h = self.conv2(graph, h)\n",
    "        h = F.relu(h)\n",
    "        h = self.dropout(h)  # Apply dropout\n",
    "        h = self.conv3(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model hyperparameters\n",
    "hidden_size = 128\n",
    "out_feats = 2  # Assuming binary classification\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # Set the random seed, a randamly selected number\n",
    "    seed = random.randint(0, 1000)\n",
    "    print(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # Create the Graphsage model\n",
    "    # Create the Graphsage model\n",
    "    model = Model(16, 128, 2, 0.1)\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    num_epochs = 100\n",
    "    patience = 20\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        labels = G_train_dgl_twitter.ndata['label'].squeeze()\n",
    "        features = G_train_dgl_twitter.ndata['combined_features']\n",
    "\n",
    "        # Select indices of 0 and 1 labels\n",
    "        zero_indices = torch.where(labels == 0)[0]\n",
    "        one_indices = torch.where(labels == 1)[0]\n",
    "        \n",
    "        # Get the minimum count between 0 and 1 labels\n",
    "        min_count = min(zero_indices.shape[0], one_indices.shape[0])\n",
    "        \n",
    "        # Randomly select 'min_count' indices from zero_indices and one_indices each\n",
    "        selected_zero_indices = zero_indices[torch.randperm(zero_indices.shape[0])[:min_count]]\n",
    "        selected_one_indices = one_indices[torch.randperm(one_indices.shape[0])[:min_count]]\n",
    "\n",
    "        # Combine the selected indices\n",
    "        selected_indices = torch.cat((selected_zero_indices, selected_one_indices))\n",
    "\n",
    "        # Shuffle the selected indices\n",
    "        selected_indices = selected_indices[torch.randperm(selected_indices.shape[0])]\n",
    "\n",
    "        # Create a subgraph from the selected indices\n",
    "        subgraph = dgl.node_subgraph(G_train_dgl_twitter, selected_indices)\n",
    "\n",
    "        # Get the selected features and labels\n",
    "        selected_features = subgraph.ndata['combined_features']\n",
    "        selected_labels = subgraph.ndata['label'].squeeze()\n",
    "\n",
    "        # Forward pass and compute the loss\n",
    "        logits = model(subgraph, selected_features.float())\n",
    "        labels = F.one_hot(selected_labels, num_classes=out_feats).float()\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Create balanced validation set\n",
    "            labels = G_val_dgl_twitter.ndata['label'].squeeze()\n",
    "\n",
    "            # Select indices of 0 and 1 labels\n",
    "            zero_indices = torch.where(labels == 0)[0]\n",
    "            one_indices = torch.where(labels == 1)[0]\n",
    "\n",
    "            # Get the minimum count between 0 and 1 labels\n",
    "            min_count = min(zero_indices.shape[0], one_indices.shape[0])\n",
    "\n",
    "            # Randomly select 'min_count' indices from zero_indices and one_indices each\n",
    "            selected_zero_indices = zero_indices[torch.randperm(zero_indices.shape[0])[:min_count]]\n",
    "            selected_one_indices = one_indices[torch.randperm(one_indices.shape[0])[:min_count]]\n",
    "\n",
    "            # Combine the selected indices\n",
    "            selected_indices = torch.cat((selected_zero_indices, selected_one_indices))\n",
    "\n",
    "            # Shuffle the selected indices\n",
    "            selected_indices = selected_indices[torch.randperm(selected_indices.shape[0])]\n",
    "\n",
    "            # Create a subgraph from the selected indices\n",
    "            subgraph = dgl.node_subgraph(G_val_dgl_twitter, selected_indices)\n",
    "\n",
    "            # Get the selected features and labels\n",
    "            selected_features = subgraph.ndata['combined_features']\n",
    "            selected_labels = subgraph.ndata['label'].squeeze()\n",
    "\n",
    "            # Validation\n",
    "            logits = model(subgraph, selected_features.float())\n",
    "            labels = F.one_hot(selected_labels, num_classes=out_feats).float()\n",
    "            val_loss = criterion(logits, labels)\n",
    "            \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(f\"Epoch: {epoch + 1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Create balanced testing set\n",
    "        labels = G_test_dgl_twitter.ndata['label'].squeeze()\n",
    "\n",
    "        # Select indices of 0 and 1 labels\n",
    "        zero_indices = torch.where(labels == 0)[0]\n",
    "        one_indices = torch.where(labels == 1)[0]\n",
    "\n",
    "        # Get the minimum count between 0 and 1 labels\n",
    "        min_count = min(zero_indices.shape[0], one_indices.shape[0])\n",
    "\n",
    "        # Randomly select 'min_count' indices from zero_indices and one_indices each\n",
    "        selected_zero_indices = zero_indices[torch.randperm(zero_indices.shape[0])[:min_count]]\n",
    "        selected_one_indices = one_indices[torch.randperm(one_indices.shape[0])[:min_count]]\n",
    "\n",
    "        # Combine the selected indices\n",
    "        selected_indices = torch.cat((selected_zero_indices, selected_one_indices))\n",
    "\n",
    "        # Shuffle the selected indices\n",
    "        selected_indices = selected_indices[torch.randperm(selected_indices.shape[0])]\n",
    "\n",
    "        # Create a subgraph from the selected indices\n",
    "        subgraph = dgl.node_subgraph(G_test_dgl_twitter, selected_indices)\n",
    "\n",
    "        # Get the selected features and labels\n",
    "        selected_features = subgraph.ndata['combined_features']\n",
    "        ground_truth = subgraph.ndata['label'].squeeze()\n",
    "\n",
    "        # Testing\n",
    "        logits = best_model(subgraph, selected_features.float())\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "        # Calculate additional evaluation metrics for testing\n",
    "        predicted_probs = F.softmax(logits, dim=1)[:, 1]\n",
    "        predicted_labels = (predicted_probs > 0.5).float()\n",
    "        auc = roc_auc_score(ground_truth.detach().numpy(), predicted_probs.detach().numpy())\n",
    "        f1 = f1_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy())\n",
    "        precision = precision_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy())\n",
    "        recall = recall_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy())\n",
    "        accuracy = accuracy_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy())\n",
    "        macro_f1 = f1_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy(), average='macro')\n",
    "        macro_precision = precision_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy(), average='macro')\n",
    "        macro_recall = recall_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy(), average='macro')\n",
    "        # store results in a txt file\n",
    "        with open(\"Graphsage_with_results.txt\", \"a\") as f:\n",
    "            # need to write random seed, validation loss, test loss, auc, f1, precision, recall\n",
    "            f.write(f\"Random seed: {seed}, Epoch: {epoch + 1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}, AUC: {auc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, Macro-F1: {macro_f1:.4f}, Macro-Precision: {macro_precision:.4f}, Macro-recall: {macro_recall:.4f}\\n\")\n",
    "        print(f\"AUC: {auc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, Macro-F1: {macro_f1:.4f}, Macro-Precision: {macro_precision:.4f}, Macro-recall: {macro_recall:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
