{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import csv\n",
    "from torch_geometric.nn import Node2Vec\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.exceptions import UndefinedMetricWarning, ConvergenceWarning\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read G_train_dgl, G_val_dgl, G_test_dgl, use pickle to read\n",
    "with open('G_train.gpickle', 'rb') as f:\n",
    "    G_train = pkl.load(f)\n",
    "    \n",
    "with open('G_val.gpickle', 'rb') as f:\n",
    "    G_val = pkl.load(f)\n",
    "    \n",
    "with open('G_test.gpickle', 'rb') as f:\n",
    "    G_test = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print G_train_dgl information\n",
    "print(G_train_dgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some label examples\n",
    "print(G_train_dgl.ndata['label'][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 10 nodes in G_train_dgl\n",
    "print(G_train_dgl.nodes()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print G_train_dgl node number\n",
    "print(G_train_dgl.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print G_LP_connected_dgl first 10 nodes\n",
    "print(G_LP_connected.nodes()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract train_positive examples, train_negative examples, val_positive examples, val_negative examples, test_positive examples, test_negative examples\n",
    "train_positive = []\n",
    "train_negative = []\n",
    "val_positive = []\n",
    "val_negative = []\n",
    "test_positive = []\n",
    "test_negative = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run node2vec on the whole connected graph, get each node's embedding and store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load G_LP_connected\n",
    "with open('G_LP_connected.gpickle', 'rb') as f:\n",
    "    G_LP_connected = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print information of G_LP_connected\n",
    "print(G_LP_connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether G_LP_connected is weakly_connected\n",
    "print(nx.is_weakly_connected(G_LP_connected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 10 nodes in G_LP_connected\n",
    "print(list(G_LP_connected.nodes())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert G_LP_connected to dgl graph\n",
    "import dgl\n",
    "\n",
    "# Create a mapping from NetworkX node (address) to DGL node (integer)\n",
    "address_to_dgl_node = {address: i for i, address in enumerate(G_LP_connected.nodes())}\n",
    "\n",
    "# Also create the inverse mapping from DGL node (integer) to NetworkX node (address)\n",
    "dgl_node_to_address = {i: address for address, i in address_to_dgl_node.items()}\n",
    "\n",
    "# Convert NetworkX graph to DGL graph\n",
    "G_LP_connected_dgl = dgl.from_networkx(G_LP_connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the mappings\n",
    "with open('address_to_dgl_node.pkl', 'wb') as f:\n",
    "    pickle.dump(address_to_dgl_node, f)\n",
    "\n",
    "with open('dgl_node_to_address.pkl', 'wb') as f:\n",
    "    pickle.dump(dgl_node_to_address, f)\n",
    "\n",
    "# Load the mappings\n",
    "with open('address_to_dgl_node.pkl', 'rb') as f:\n",
    "    address_to_dgl_node = pickle.load(f)\n",
    "\n",
    "with open('dgl_node_to_address.pkl', 'rb') as f:\n",
    "    dgl_node_to_address = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save G_LP_connected_dgl\n",
    "with open('G_LP_connected_dgl.pkl', 'wb') as f:\n",
    "    pickle.dump(G_LP_connected_dgl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some examples of address_to_dgl_node\n",
    "print(list(address_to_dgl_node.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some examples of dgl_node_to_address\n",
    "print(list(dgl_node_to_address.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print information of G_LP_connected_dgl\n",
    "print(G_LP_connected_dgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print G_LP_connected_dgl some nodes and edges\n",
    "print(G_LP_connected_dgl.nodes()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print G_LP_connected_dgl edges examples first 10\n",
    "print(G_LP_connected_dgl.edges()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print edge_index of the dgl graph\n",
    "print(G_LP_connected_dgl.edges()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get edge indices from your DGL graph\n",
    "src, dst = G_LP_connected_dgl.edges()\n",
    "\n",
    "# Create edge_index tensor\n",
    "edge_index = torch.tensor([src.tolist(), dst.tolist()], dtype=torch.long).contiguous().to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a deepwalk model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Node2Vec(edge_index, embedding_dim=128, walk_length=20, context_size=5, walks_per_node=40, num_negative_samples=1, sparse=True,).to(device)\n",
    "loader = model.loader(batch_size=128, shuffle=True, num_workers=4)\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    scaler = GradScaler()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Node2Vec(edge_index, embedding_dim=128, walk_length=20, context_size=5, walks_per_node=40, num_negative_samples=1, sparse=True,).to(device)\n",
    "loader = model.loader(batch_size=128, shuffle=True, num_workers=4)\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train in 100 epochs\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    print('Epoch: {:02d}, Loss: {:.4f}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store embeddings\n",
    "embeddings = model(torch.arange(edge_index.max().item() + 1).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a loop to do training, and store embeddings for 5 times for later use\n",
    "for i in range(5):\n",
    "    # set device to cuda:1\n",
    "    device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "    print('training round: ', i)\n",
    "    model = Node2Vec(edge_index, embedding_dim=128, walk_length=20, context_size=5, walks_per_node=40, num_negative_samples=1, sparse=True,).to(device)\n",
    "    loader = model.loader(batch_size=128, shuffle=True, num_workers=4)\n",
    "    optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.001)\n",
    "    for epoch in range(1, 101):\n",
    "        loss = train()\n",
    "        print('Epoch: {:02d}, Loss: {:.4f}'.format(epoch, loss))\n",
    "    \n",
    "    print('finish training round: ', i)\n",
    "    \n",
    "    # store embeddings\n",
    "    embeddings = model(torch.arange(edge_index.max().item() + 1).to(device))\n",
    "    \n",
    "    # save embeddings\n",
    "    with open('deepwalk_embeddings_' + str(i+1) + '.pkl', 'wb') as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "        \n",
    "    print('finish saving embeddings: ', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load G_train.dgl, G_test.dgl\n",
    "with open('G_train_dgl.gpickle', 'rb') as f:\n",
    "    G_train_dgl = pkl.load(f)\n",
    "    \n",
    "with open('G_test_dgl.gpickle', 'rb') as f:\n",
    "    G_test_dgl = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dgl_node_to_address.pkl\n",
    "with open('dgl_node_to_address.pkl', 'rb') as f:\n",
    "    dgl_node_to_address = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some examples of dgl_node_to_address\n",
    "print(list(dgl_node_to_address.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print last examples of dgl_node_to_address\n",
    "print(list(dgl_node_to_address.items())[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load address_to_dgl_node.pkl\n",
    "with open('address_to_dgl_node.pkl', 'rb') as f:\n",
    "    address_to_dgl_node = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some examples of address_to_dgl_node, first and last some examples\n",
    "print(list(address_to_dgl_node.items())[0:10])\n",
    "print(list(address_to_dgl_node.items())[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print G_train_dgl some nodes and edges\n",
    "print(G_train_dgl.nodes()[0:10])\n",
    "print(G_test_dgl.nodes()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load G_train, G_test\n",
    "with open('G_train.gpickle', 'rb') as f:\n",
    "    G_train = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('G_test.gpickle', 'rb') as f:\n",
    "    G_test = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some information of G_train including nodes and edges\n",
    "print(list(G_train.nodes())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some examples of G_test including nodes and edges\n",
    "print(list(G_test.nodes())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add node labels of G_train, and G_test\n",
    "# read eoa_addr_list.txt\n",
    "with open('eoa_addr_list.txt', 'r') as f:\n",
    "    eoa_addr_list = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 10 examples of eoa_addr_list\n",
    "print(eoa_addr_list[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate G_train and add node labels\n",
    "for node in G_train.nodes():\n",
    "    if node in eoa_addr_list:\n",
    "        G_train.nodes[node]['label'] = 1\n",
    "    else:\n",
    "        G_train.nodes[node]['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add G_test node labels\n",
    "for node in G_test.nodes():\n",
    "    if node in eoa_addr_list:\n",
    "        G_test.nodes[node]['label'] = 1\n",
    "    else:\n",
    "        G_test.nodes[node]['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use logistic regression to train on G_train_dgl node embeddings for node classification\n",
    "# load deepwalk_embeddings_0.pkl\n",
    "with open('deepwalk_embeddings_0.pkl', 'rb') as f:\n",
    "    embeddings = pkl.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 1-to-1 extract label 1 and label 0 nodes, as the positive and negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 1-to-1 positive and negative examples of G_train\n",
    "train_positive = []\n",
    "train_negative = []\n",
    "\n",
    "# iterate G_train nodes and extract positive and negative examples, keep 1-to-1 ratio\n",
    "for node in G_train.nodes():\n",
    "    if G_train.nodes[node]['label'] == 1:\n",
    "        train_positive.append(node)\n",
    "\n",
    "\n",
    "# randomly sample negative examples, random choice        \n",
    "train_negative = np.random.choice(list(set(G_train.nodes()) - set(train_positive)), len(train_positive), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print examples of train_positive and train_negative\n",
    "print(train_positive[0:10])\n",
    "print(train_negative[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store train_positive and train_negative to train_positive.pkl and train_negative.pkl\n",
    "with open('train_positive.pkl', 'wb') as f:\n",
    "    pkl.dump(train_positive, f)\n",
    "    \n",
    "with open('train_negative.pkl', 'wb') as f:\n",
    "    pkl.dump(train_negative, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test, do the same operation\n",
    "test_positive = []\n",
    "test_negative = []\n",
    "\n",
    "# iterate G_test nodes and extract positive and negative examples, keep 1-to-1 ratio\n",
    "for node in G_test.nodes():\n",
    "    if G_test.nodes[node]['label'] == 1:\n",
    "        test_positive.append(node)\n",
    "        \n",
    "# randomly sample negative examples, random choice\n",
    "test_negative = np.random.choice(list(set(G_test.nodes()) - set(test_positive)), len(test_positive), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test_positive and test_negative examples\n",
    "print(test_positive[0:10])\n",
    "print(test_negative[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store test_positive and test_negative to test_positive.pkl and test_negative.pkl\n",
    "with open('test_positive.pkl', 'wb') as f:\n",
    "    pkl.dump(test_positive, f)\n",
    "    \n",
    "with open('test_negative.pkl', 'wb') as f:\n",
    "    pkl.dump(test_negative, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: use node embeddings, fit into the clf evaluate, get auc f1 precision recall accuracy macro-f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use node embeddings, fit into the clf evaluate, get auc f1 precision recall accuracy macro-f1\n",
    "# load train_positive.pkl and train_negative.pkl\n",
    "\n",
    "with open('train_positive.pkl', 'rb') as f:\n",
    "    train_positive = pkl.load(f)\n",
    "    \n",
    "with open('train_negative.pkl', 'rb') as f:\n",
    "    train_negative = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print train_positive and train_negative examples\n",
    "print(train_positive[0:10])\n",
    "print(train_negative[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test_positive.pkl and test_negative.pkl\n",
    "with open('test_positive.pkl', 'rb') as f:\n",
    "    test_positive = pkl.load(f)\n",
    "    \n",
    "with open('test_negative.pkl', 'rb') as f:\n",
    "    test_negative = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test_positive and test_negative examples\n",
    "print(test_positive[0:10])\n",
    "print(test_negative[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get node embeddings of the node in train_positive and train_negative, and use logistic regression to train and evaluate\n",
    "# load deepwalk_embeddings_0.pkl\n",
    "# set device to cuda:6\n",
    "device = torch.device('cuda:6' if torch.cuda.is_available() else 'cpu')\n",
    "with open('deepwalk_embeddings_0.pkl', 'rb') as f:\n",
    "    embeddings = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print embeddings information\n",
    "print(embeddings[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the clf\n",
    "clf = LogisticRegression(random_state=0, max_iter=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive_embeddings = []\n",
    "for node in train_positive:\n",
    "    train_positive_embeddings.append(embeddings[address_to_dgl_node[node]].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print train_positive_embeddings first 10 examples\n",
    "print(train_positive_embeddings[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also do the same operation for train_negative\n",
    "train_negative_embeddings = []\n",
    "for node in train_negative:\n",
    "    train_negative_embeddings.append(embeddings[address_to_dgl_node[node]].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use StandardScaler to scale train_positive_embeddings and train_negative_embeddings\n",
    "scaler = StandardScaler()\n",
    "train_positive_embeddings = scaler.fit_transform(train_positive_embeddings)\n",
    "train_negative_embeddings = scaler.fit_transform(train_negative_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store embeddings and labels\n",
    "train_positive_embeddings = []\n",
    "train_negative_embeddings = []\n",
    "\n",
    "# Assuming 'embeddings' holds your precomputed node embeddings and 'address_to_dgl_node' maps addresses to node IDs\n",
    "for node in train_positive:\n",
    "    train_positive_embeddings.append(embeddings[address_to_dgl_node[node]].detach().cpu().numpy())\n",
    "\n",
    "for node in train_negative:\n",
    "    train_negative_embeddings.append(embeddings[address_to_dgl_node[node]].detach().cpu().numpy())\n",
    "\n",
    "# Combine positive and negative embeddings\n",
    "train_nodes_embeddings = train_positive_embeddings + train_negative_embeddings\n",
    "\n",
    "# Create corresponding labels\n",
    "train_nodes_labels = [1] * len(train_positive_embeddings) + [0] * len(train_negative_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of train_nodes_embeddings and train_nodes_labels\n",
    "print(len(train_nodes_embeddings))\n",
    "print(len(train_nodes_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of 1 and 0 in train_nodes_labels\n",
    "print(train_nodes_labels.count(1))\n",
    "print(train_nodes_labels.count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the clf\n",
    "clf.fit(train_nodes_embeddings, train_nodes_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test_positive and test_negative\n",
    "test_positive_embeddings = []\n",
    "for node in test_positive:\n",
    "    test_positive_embeddings.append(embeddings[address_to_dgl_node[node]].detach().cpu().numpy())\n",
    "    \n",
    "test_negative_embeddings = []\n",
    "for node in test_negative:\n",
    "    test_negative_embeddings.append(embeddings[address_to_dgl_node[node]].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some examples of test_positive_embeddings and test_negative_embeddings\n",
    "print(test_positive_embeddings[0:10])\n",
    "print(test_negative_embeddings[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of test_positive_embeddings and test_negative_embeddings\n",
    "print(len(test_positive_embeddings))\n",
    "print(len(test_negative_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine test_positive_embeddings and test_negative_embeddings\n",
    "test_nodes_embeddings = test_positive_embeddings + test_negative_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 10 examples of test_nodes_embeddings\n",
    "print(test_nodes_embeddings[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of test_nodes_embeddings\n",
    "print(len(test_nodes_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf predict on test_nodes_embeddings, first get all labels\n",
    "\n",
    "# Generate labels for the test dataset: 1 for positive and 0 for negative\n",
    "test_nodes_labels = [1] * len(test_positive_embeddings) + [0] * len(test_negative_embeddings)\n",
    "\n",
    "\n",
    "# predict on test_nodes_embeddings\n",
    "test_nodes_predictions = clf.predict(test_nodes_embeddings)\n",
    "\n",
    "\n",
    "# compute auc, f1, precision, recall, accuracy, macro-f1\n",
    "auc = roc_auc_score(test_nodes_labels, test_nodes_predictions)\n",
    "f1 = f1_score(test_nodes_labels, test_nodes_predictions)\n",
    "precision = precision_score(test_nodes_labels, test_nodes_predictions)\n",
    "recall = recall_score(test_nodes_labels, test_nodes_predictions)\n",
    "accuracy = (test_nodes_predictions == test_nodes_labels).mean()\n",
    "macro_f1 = f1_score(test_nodes_labels, test_nodes_predictions, average='macro')\n",
    "\n",
    "# print auc, f1, precision, recall, accuracy, macro_f1\n",
    "print('auc: ', auc)\n",
    "print('f1: ', f1)\n",
    "print('precision: ', precision)\n",
    "print('recall: ', recall)\n",
    "print('accuracy: ', accuracy)\n",
    "print('macro_f1: ', macro_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
