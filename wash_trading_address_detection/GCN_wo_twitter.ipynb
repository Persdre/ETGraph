{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"temporal_graph_filtered_weighted.gpickle\", \"rb\") as f:\n",
    "    G = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"digraph_temporal_LP.gpickle\", \"rb\") as f:\n",
    "    G_LP = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the information of G_LP\n",
    "print(G_LP.number_of_nodes())\n",
    "print(G_LP.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 10 edges of G_LP\n",
    "print(list(G_LP.edges(data=True))[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the largest weakly connected component of the graph, with all edges data\n",
    "Gcc = sorted(nx.weakly_connected_components(G_LP), key=len, reverse=True)\n",
    "\n",
    "# Get the largest weakly connected component of the graph\n",
    "G_LP_connected = G_LP.subgraph(Gcc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print nodes and edges number of G_LP_connected\n",
    "print(G_LP_connected.number_of_nodes())\n",
    "print(G_LP_connected.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some edges of G_LP_connected\n",
    "print(list(G_LP_connected.edges(data=True))[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split all nodes into train, validation and test sets\n",
    "# train:validation:test = 0.7:0.1:0.2\n",
    "\n",
    "# get all nodes\n",
    "nodes = list(G_LP_connected.nodes())\n",
    "\n",
    "# randomly shuffle nodes\n",
    "np.random.shuffle(nodes)\n",
    "\n",
    "# split nodes into train, validation and test sets\n",
    "train_nodes = nodes[0:int(len(nodes)*0.7)]\n",
    "\n",
    "validation_nodes = nodes[int(len(nodes)*0.7):int(len(nodes)*0.8)]\n",
    "\n",
    "test_nodes = nodes[int(len(nodes)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load eoa_addr_list.txt\n",
    "eoa_addr_list = []\n",
    "with open(\"eoa_addr_list.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        eoa_addr_list.append(line.strip())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_nodes, validation_nodes and test_nodes get all nodes appear in the phishing account list\n",
    "train_nodes_phishing = []\n",
    "for node in train_nodes:\n",
    "    if node in eoa_addr_list:\n",
    "        train_nodes_phishing.append(node)\n",
    "        \n",
    "validation_nodes_phishing = []\n",
    "for node in validation_nodes:\n",
    "    if node in eoa_addr_list:\n",
    "        validation_nodes_phishing.append(node)\n",
    "        \n",
    "test_nodes_phishing = []\n",
    "for node in test_nodes:\n",
    "    if node in eoa_addr_list:\n",
    "        test_nodes_phishing.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print how many phishing accounts in train, validation and test sets\n",
    "print(len(train_nodes_phishing))\n",
    "print(len(validation_nodes_phishing))\n",
    "print(len(test_nodes_phishing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store train_nodes_phishing, validation_nodes_phishing and test_nodes_phishing to txt files\n",
    "with open(\"train_nodes_wt.txt\", \"w\") as f:\n",
    "    for node in train_nodes_phishing:\n",
    "        f.write(node + \"\\n\")\n",
    "        \n",
    "with open(\"validation_nodes_wt.txt\", \"w\") as f:\n",
    "    for node in validation_nodes_phishing:\n",
    "        f.write(node + \"\\n\")\n",
    "        \n",
    "with open(\"test_nodes_wt.txt\", \"w\") as f:\n",
    "    for node in test_nodes_phishing:\n",
    "        f.write(node + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_nodes_normal = []\n",
    "# the same number of normal accounts as train_nodes_phishing\n",
    "train_node_num = len(train_nodes_phishing)\n",
    "\n",
    "for node in train_nodes:\n",
    "    if node not in eoa_addr_list:\n",
    "        train_nodes_normal.append(node)\n",
    "        if len(train_nodes_normal) == train_node_num:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some examples in train_nodes_normal\n",
    "print(train_nodes_normal[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store train_nodes_normal to txt file\n",
    "with open(\"train_nodes_normal.txt\", \"w\") as f:\n",
    "    for node in train_nodes_normal:\n",
    "        f.write(node + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same thing for validation_nodes_phishing and test_nodes_phishing\n",
    "validation_nodes_normal = []\n",
    "\n",
    "validation_node_num = len(validation_nodes_phishing)\n",
    "\n",
    "for node in validation_nodes:\n",
    "    if node not in eoa_addr_list:\n",
    "        validation_nodes_normal.append(node)\n",
    "        if len(validation_nodes_normal) == validation_node_num:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store validation_nodes_normal to txt file\n",
    "with open(\"validation_nodes_normal.txt\", \"w\") as f:\n",
    "    for node in validation_nodes_normal:\n",
    "        f.write(node + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same thing for test_nodes_phishing\n",
    "test_nodes_normal = []\n",
    "\n",
    "test_node_num = len(test_nodes_phishing)\n",
    "\n",
    "for node in test_nodes:\n",
    "    if node not in eoa_addr_list:\n",
    "        test_nodes_normal.append(node)\n",
    "        if len(test_nodes_normal) == test_node_num:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store test_nodes_normal to txt file\n",
    "with open(\"test_nodes_normal.txt\", \"w\") as f:\n",
    "    for node in test_nodes_normal:\n",
    "        f.write(node + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some examples of phishing accounts in train, validation and test sets\n",
    "print(train_nodes_phishing[0:10])\n",
    "print(validation_nodes_phishing[0:10])\n",
    "print(test_nodes_phishing[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for G_LP_connected, add node attributes: label, train_pos, train_neg, validation_pos, validation_neg, test_pos, test_neg\n",
    "# label: 1 for phishing accounts, 0 for normal accounts\n",
    "\n",
    "# add node attribute: label\n",
    "for node in G_LP_connected.nodes():\n",
    "    if node in eoa_addr_list:\n",
    "        G_LP_connected.nodes[node][\"label\"] = 1\n",
    "    else:\n",
    "        G_LP_connected.nodes[node][\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add node attribute: train_pos, train_neg, validation_pos, validation_neg, test_pos, test_neg\n",
    "for node in G_LP_connected.nodes():\n",
    "    if node in train_nodes_phishing:\n",
    "        G_LP_connected.nodes[node][\"train_pos\"] = 1\n",
    "    else:\n",
    "        G_LP_connected.nodes[node][\"train_pos\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add node attributes: train_pos, train_neg, validation_pos, validation_neg, test_pos, test_neg\n",
    "for node in G_LP_connected.nodes():\n",
    "    # Add attribute: train_pos\n",
    "    if node in train_nodes_phishing:\n",
    "        G_LP_connected.nodes[node][\"train_pos\"] = 1\n",
    "    else:\n",
    "        G_LP_connected.nodes[node][\"train_pos\"] = 0\n",
    "\n",
    "    # Add attribute: train_neg\n",
    "    if node in train_nodes_normal:\n",
    "        G_LP_connected.nodes[node][\"train_neg\"] = 1\n",
    "    else:\n",
    "        G_LP_connected.nodes[node][\"train_neg\"] = 0\n",
    "\n",
    "    # Add attribute: validation_pos\n",
    "    if node in validation_nodes_phishing:\n",
    "        G_LP_connected.nodes[node][\"validation_pos\"] = 1\n",
    "    else:\n",
    "        G_LP_connected.nodes[node][\"validation_pos\"] = 0\n",
    "\n",
    "    # Add attribute: validation_neg\n",
    "    if node in validation_nodes_normal:\n",
    "        G_LP_connected.nodes[node][\"validation_neg\"] = 1\n",
    "    else:\n",
    "        G_LP_connected.nodes[node][\"validation_neg\"] = 0\n",
    "\n",
    "    # Add attribute: test_pos\n",
    "    if node in test_nodes_phishing:\n",
    "        G_LP_connected.nodes[node][\"test_pos\"] = 1\n",
    "    else:\n",
    "        G_LP_connected.nodes[node][\"test_pos\"] = 0\n",
    "\n",
    "    # Add attribute: test_neg\n",
    "    if node in test_nodes_normal:\n",
    "        G_LP_connected.nodes[node][\"test_neg\"] = 1\n",
    "    else:\n",
    "        G_LP_connected.nodes[node][\"test_neg\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NodeView to a list\n",
    "node_list = list(G_LP_connected.nodes())\n",
    "\n",
    "# Print attributes of the first 5 nodes\n",
    "for node in node_list[:5]:\n",
    "    print(G_LP_connected.nodes[node])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get all structural features of nodes\n",
    "def calculate_average_neighbor_degree(node, graph):\n",
    "    neighbors = set(graph.predecessors(node)) | set(graph.successors(node))\n",
    "    total_neighbor_degree = sum([graph.degree(neighbor) for neighbor in neighbors])\n",
    "    \n",
    "    if len(neighbors) > 0:\n",
    "        average_neighbor_degree = total_neighbor_degree / len(neighbors)\n",
    "    else:\n",
    "        average_neighbor_degree = 0\n",
    "    \n",
    "    return average_neighbor_degree\n",
    "\n",
    "\n",
    "def node_feature_func(node, G):\n",
    "    # Get neighbors\n",
    "    neighbors = list(G.neighbors(node))  # Out-neighbors\n",
    "    in_neighbors = list(G.predecessors(node))  # In-neighbors\n",
    "    all_neighbors = list(set(neighbors + in_neighbors))  # Both in-neighbors and out-neighbors\n",
    "\n",
    "    degree = G.degree(node)\n",
    "    in_degree = G.in_degree(node)\n",
    "    out_degree = G.out_degree(node)\n",
    "\n",
    "    # Check if neighbors exist\n",
    "    if all_neighbors:\n",
    "        in_transactions = [G[neighbor][node].get('weight', 1) for neighbor in in_neighbors]\n",
    "        out_transactions = [G[node][neighbor].get('weight', 1) for neighbor in neighbors]\n",
    "        all_transactions = in_transactions + out_transactions\n",
    "        max_transactions = max(all_transactions)\n",
    "    else:\n",
    "        max_transactions = 0\n",
    "\n",
    "    avg_neighbor_degree = calculate_average_neighbor_degree(node, G)\n",
    "\n",
    "    return [degree, in_degree, out_degree, len(neighbors), len(in_neighbors), len(all_neighbors), max_transactions, avg_neighbor_degree]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# apply the function to all nodes in G_LP_connected\n",
    "for node in tqdm(G_LP_connected.nodes(), total=len(G_LP_connected)):\n",
    "    G_LP_connected.nodes[node]['features'] = node_feature_func(node, G_LP_connected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some examples of nodes and their features\n",
    "print(list(G_LP_connected.nodes(data=True))[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Convert your list to a NumPy array for Scikit-Learn, if it isn't already\n",
    "node_features = np.array(node_features)\n",
    "\n",
    "# Initialize a scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to your data and transform it\n",
    "normalized_features = scaler.fit_transform(node_features)\n",
    "\n",
    "# Store the normalized features back into the nodes\n",
    "for node, features in zip(node_list, normalized_features):\n",
    "    G_LP_connected.nodes[node][\"features\"] = features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for G_train, G_val, G_test, add node labels\n",
    "# label the nodes of G_LP_connected, if appear in eoa_addr_list.txt, label 1, else label 0\n",
    "# load eoa_addr_list.txt\n",
    "eoa_addr_list = []\n",
    "with open(\"eoa_addr_list.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        eoa_addr_list.append(line.strip())\n",
    "        \n",
    "# label the nodes of G_train, G_val, G_test, if appear in eoa_addr_list.txt, label 1, else label 0\n",
    "for node in G_train.nodes():\n",
    "    if node in eoa_addr_list:\n",
    "        G_train.nodes[node]['label'] = 1\n",
    "        print(node)\n",
    "    else:\n",
    "        G_train.nodes[node]['label'] = 0\n",
    "        \n",
    "\n",
    "for node in G_val.nodes():\n",
    "    if node in eoa_addr_list:\n",
    "        G_val.nodes[node]['label'] = 1\n",
    "        print(node)\n",
    "    else:\n",
    "        G_val.nodes[node]['label'] = 0\n",
    "        \n",
    "\n",
    "for node in G_test.nodes():\n",
    "    if node in eoa_addr_list:\n",
    "        G_test.nodes[node]['label'] = 1\n",
    "        print(node)\n",
    "    else:\n",
    "        G_test.nodes[node]['label'] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Get the largest weakly connected component of the graph, with all edges data\n",
    "Gcc = sorted(nx.weakly_connected_components(G_LP), key=len, reverse=True)\n",
    "\n",
    "# Get the largest weakly connected component of the graph\n",
    "G_LP_connected = G_LP.subgraph(Gcc[0])\n",
    "\n",
    "# Convert edges to list for easier manipulation\n",
    "edges = list(G_LP_connected.edges(data=True))\n",
    "\n",
    "# Extract block numbers from edges\n",
    "block_numbers = [d['block_number'] for _, _, d in edges]\n",
    "sorted_edge_indexes = np.argsort(block_numbers)  # Sort edges by block numbers\n",
    "\n",
    "# Compute the sizes of train/validation/test sets\n",
    "total_edges = len(edges)\n",
    "train_size = int(total_edges * 0.7)\n",
    "val_size = int(total_edges * 0.1)\n",
    "test_size = total_edges - train_size - val_size  # Rest of the edges\n",
    "\n",
    "# Divide edges into train/validation/test\n",
    "train_edges = [edges[i] for i in sorted_edge_indexes[:train_size]]\n",
    "val_edges = [edges[i] for i in sorted_edge_indexes[train_size:train_size+val_size]]\n",
    "test_edges = [edges[i] for i in sorted_edge_indexes[train_size+val_size:]]\n",
    "\n",
    "# Create train/validation/test graphs\n",
    "G_train = nx.DiGraph()\n",
    "G_val = nx.DiGraph()\n",
    "G_test = nx.DiGraph()\n",
    "\n",
    "for e in train_edges:\n",
    "    G_train.add_edge(e[0], e[1], block_number=e[2]['block_number'], weight=e[2]['weight'])\n",
    "\n",
    "for e in val_edges:\n",
    "    G_val.add_edge(e[0], e[1], block_number=e[2]['block_number'], weight=e[2]['weight'])\n",
    "\n",
    "for e in test_edges:\n",
    "    G_test.add_edge(e[0], e[1], block_number=e[2]['block_number'], weight=e[2]['weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for G_train, G_val, G_test, add node labels\n",
    "# label the nodes of G_LP_connected, if appear in eoa_addr_list.txt, label 1, else label 0\n",
    "# load eoa_addr_list.txt\n",
    "eoa_addr_list = []\n",
    "with open(\"eoa_addr_list.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        eoa_addr_list.append(line.strip())\n",
    "        \n",
    "# label the nodes of G_train, G_val, G_test, if appear in eoa_addr_list.txt, label 1, else label 0\n",
    "for node in G_train.nodes():\n",
    "    if node in eoa_addr_list:\n",
    "        G_train.nodes[node]['label'] = 1\n",
    "        print(node)\n",
    "    else:\n",
    "        G_train.nodes[node]['label'] = 0\n",
    "        \n",
    "\n",
    "for node in G_val.nodes():\n",
    "    if node in eoa_addr_list:\n",
    "        G_val.nodes[node]['label'] = 1\n",
    "        print(node)\n",
    "    else:\n",
    "        G_val.nodes[node]['label'] = 0\n",
    "        \n",
    "\n",
    "for node in G_test.nodes():\n",
    "    if node in eoa_addr_list:\n",
    "        G_test.nodes[node]['label'] = 1\n",
    "        print(node)\n",
    "    else:\n",
    "        G_test.nodes[node]['label'] = 0\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print G_train, G_val, G_test information of nodes, edges, and edge data\n",
    "print(G_train.number_of_nodes())\n",
    "print(G_train.number_of_edges())\n",
    "print(list(G_train.edges(data=True))[0:10])\n",
    "\n",
    "print(G_val.number_of_nodes())\n",
    "print(G_val.number_of_edges())\n",
    "print(list(G_val.edges(data=True))[0:10])\n",
    "\n",
    "print(G_test.number_of_nodes())\n",
    "print(G_test.number_of_edges())\n",
    "print(list(G_test.edges(data=True))[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all neighbors of 0x47b81da0bbe08cb3ae51cd378ab060a0fcd51338\n",
    "neighbors = list(G_train.neighbors('0x47b81da0bbe08cb3ae51cd378ab060a0fcd51338'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train['0x47b81da0bbe08cb3ae51cd378ab060a0fcd51338'][neighbors[0]]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check degree of 0x47b81da0bbe08cb3ae51cd378ab060a0fcd51338\n",
    "G_train.degree('0x47b81da0bbe08cb3ae51cd378ab060a0fcd51338')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check in-degree of 0x47b81da0bbe08cb3ae51cd378ab060a0fcd51338\n",
    "G_train.in_degree('0x47b81da0bbe08cb3ae51cd378ab060a0fcd51338')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump G_train, G_val, G_test\n",
    "with open(\"G_train.gpickle\", \"wb\") as f:\n",
    "    pickle.dump(G_train, f)\n",
    "    \n",
    "with open(\"G_val.gpickle\", \"wb\") as f:\n",
    "    pickle.dump(G_val, f)\n",
    "    \n",
    "with open(\"G_test.gpickle\", \"wb\") as f:\n",
    "    pickle.dump(G_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_neighbor_degree(node, graph):\n",
    "    neighbors = set(graph.predecessors(node)) | set(graph.successors(node))\n",
    "    total_neighbor_degree = sum([graph.degree(neighbor) for neighbor in neighbors])\n",
    "    \n",
    "    if len(neighbors) > 0:\n",
    "        average_neighbor_degree = total_neighbor_degree / len(neighbors)\n",
    "    else:\n",
    "        average_neighbor_degree = 0\n",
    "    \n",
    "    return average_neighbor_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_neighbor_degree(node, graph):\n",
    "    neighbors = set(graph.predecessors(node)) | set(graph.successors(node))\n",
    "    total_neighbor_degree = sum([graph.degree(neighbor) for neighbor in neighbors])\n",
    "    \n",
    "    if len(neighbors) > 0:\n",
    "        average_neighbor_degree = total_neighbor_degree / len(neighbors)\n",
    "    else:\n",
    "        average_neighbor_degree = 0\n",
    "    \n",
    "    return average_neighbor_degree\n",
    "\n",
    "\n",
    "def node_feature_func(node, G):\n",
    "    # Get neighbors\n",
    "    neighbors = list(G.neighbors(node))  # Out-neighbors\n",
    "    in_neighbors = list(G.predecessors(node))  # In-neighbors\n",
    "    all_neighbors = list(set(neighbors + in_neighbors))  # Both in-neighbors and out-neighbors\n",
    "\n",
    "    degree = G.degree(node)\n",
    "    in_degree = G.in_degree(node)\n",
    "    out_degree = G.out_degree(node)\n",
    "\n",
    "    # Check if neighbors exist\n",
    "    if all_neighbors:\n",
    "        in_transactions = [G[neighbor][node].get('weight', 1) for neighbor in in_neighbors]\n",
    "        out_transactions = [G[node][neighbor].get('weight', 1) for neighbor in neighbors]\n",
    "        all_transactions = in_transactions + out_transactions\n",
    "        max_transactions = max(all_transactions)\n",
    "    else:\n",
    "        max_transactions = 0\n",
    "\n",
    "    avg_neighbor_degree = calculate_average_neighbor_degree(node, G)\n",
    "\n",
    "    return [degree, in_degree, out_degree, len(neighbors), len(in_neighbors), len(all_neighbors), max_transactions, avg_neighbor_degree]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for G in [G_train, G_val, G_test]:\n",
    "    for node in G.nodes:\n",
    "        G.nodes[node]['features'] = node_feature_func(node, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 10 nodes in G_train, G_val, G_test\n",
    "print(list(G_train.nodes(data=True))[0:10])\n",
    "print(list(G_val.nodes(data=True))[0:10])\n",
    "print(list(G_test.nodes(data=True))[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all features, do log, then normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Get all features\n",
    "all_features = np.array([G_train.nodes[node]['features'] for node in G_train.nodes()])\n",
    "\n",
    "# Log transform all features\n",
    "all_features = np.log(all_features + 1)\n",
    "\n",
    "# Normalize all features\n",
    "scaler = StandardScaler()\n",
    "all_features = scaler.fit_transform(all_features)\n",
    "\n",
    "# Set node features\n",
    "for i, node in enumerate(G_train.nodes()):\n",
    "    G_train.nodes[node]['normalized_log_features'] = all_features[i]\n",
    "    \n",
    "for i, node in enumerate(G_val.nodes()):\n",
    "    G_val.nodes[node]['normalized_log_features'] = all_features[i]\n",
    "    \n",
    "for i, node in enumerate(G_test.nodes()):\n",
    "    G_test.nodes[node]['normalized_log_features'] = all_features[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 10 nodes in G_train, G_val, G_test\n",
    "print(list(G_train.nodes(data=True))[0:10])\n",
    "print(list(G_val.nodes(data=True))[0:10])\n",
    "print(list(G_test.nodes(data=True))[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "\n",
    "\n",
    "# Convert the graph to a DGL graph, keep node features\n",
    "\n",
    "G_train_dgl = dgl.DGLGraph(G_train)\n",
    "G_val_dgl = dgl.DGLGraph(G_val)\n",
    "G_test_dgl = dgl.DGLGraph(G_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the node features from the original graph\n",
    "node_features_train = np.array([G_train.nodes[node]['features'] for node in G_train.nodes()])\n",
    "node_features_val = np.array([G_val.nodes[node]['features'] for node in G_val.nodes()])\n",
    "node_features_test = np.array([G_test.nodes[node]['features'] for node in G_test.nodes()])\n",
    "\n",
    "# Set the node features in the DGL graph\n",
    "G_train_dgl.ndata['features'] = torch.tensor(node_features_train)\n",
    "G_val_dgl.ndata['features'] = torch.tensor(node_features_val)\n",
    "G_test_dgl.ndata['features'] = torch.tensor(node_features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print node_features_train first 10 rows\n",
    "print(node_features_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the node features in the DGL graph\n",
    "G_train_dgl.ndata['features'] = torch.tensor(node_features_train, dtype=torch.float32)\n",
    "G_val_dgl.ndata['features'] = torch.tensor(node_features_val, dtype=torch.float32)\n",
    "G_test_dgl.ndata['features'] = torch.tensor(node_features_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some examples in G_train_dgl\n",
    "print(G_train_dgl.ndata['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load G_train, G_val, G_test\n",
    "with open(\"G_train.gpickle\", \"rb\") as f:\n",
    "    G_train = pickle.load(f)\n",
    "    \n",
    "with open(\"G_val.gpickle\", \"rb\") as f:\n",
    "    G_val = pickle.load(f)\n",
    "    \n",
    "with open(\"G_test.gpickle\", \"rb\") as f:\n",
    "    G_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some nodes in G_train\n",
    "print(list(G_train.nodes(data=True))[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find how many nods both appear in G_train and G_val\n",
    "G_train_nodes = set(G_train.nodes())\n",
    "G_val_nodes = set(G_val.nodes())\n",
    "\n",
    "print(len(G_train_nodes.intersection(G_val_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print one example of node in G_train_nodes.intersection(G_val_nodes), and its features in both G_train and G_val\n",
    "node = list(G_train_nodes.intersection(G_val_nodes))[0]\n",
    "\n",
    "# print degree of node in G_train\n",
    "print(G_train.degree(node))\n",
    "\n",
    "# print degree of node in G_val\n",
    "print(G_val.degree(node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get those nodes labels, check how many nodes both label 1\n",
    "G_train_nodes = set(G_train.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels to G_train_dgl, G_val_dgl, G_test_dgl\n",
    "\n",
    "# Get the labels from the original graph\n",
    "node_labels_train = np.array([G_train.nodes[node]['label'] for node in G_train.nodes()])\n",
    "node_labels_val = np.array([G_val.nodes[node]['label'] for node in G_val.nodes()])\n",
    "node_labels_test = np.array([G_test.nodes[node]['label'] for node in G_test.nodes()])\n",
    "\n",
    "# Set the labels in the DGL graph\n",
    "G_train_dgl.ndata['label'] = torch.tensor(node_labels_train)\n",
    "G_val_dgl.ndata['label'] = torch.tensor(node_labels_val)\n",
    "G_test_dgl.ndata['label'] = torch.tensor(node_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some labels\n",
    "print(G_train_dgl.ndata['label'][0:10])\n",
    "print(G_val_dgl.ndata['label'][0:10])\n",
    "print(G_test_dgl.ndata['label'][0:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN training graph largest connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import GraphConv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import dgl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train_dgl.ndata['features'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train_dgl.ndata['features'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add self-loops to the input graphs\n",
    "G_train_dgl = dgl.add_self_loop(G_train_dgl)\n",
    "G_val_dgl = dgl.add_self_loop(G_val_dgl)\n",
    "G_test_dgl = dgl.add_self_loop(G_test_dgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print check how many 1 and how many 0 in G_test_dgl.ndata['label']\n",
    "\n",
    "print(G_test_dgl.ndata['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print check how many 1 and how many 0 in G_test_dgl.ndata['label']\n",
    "print(G_test_dgl.ndata['label'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store G_train_dgl, G_val_dgl, G_test_dgl\n",
    "with open(\"G_train_dgl.gpickle\", \"wb\") as f:\n",
    "    pickle.dump(G_train_dgl, f)\n",
    "    \n",
    "with open(\"G_val_dgl.gpickle\", \"wb\") as f:\n",
    "    pickle.dump(G_val_dgl, f)\n",
    "    \n",
    "with open(\"G_test_dgl.gpickle\", \"wb\") as f:\n",
    "    pickle.dump(G_test_dgl, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read G_train_dgl, G_val_dgl, G_test_dgl\n",
    "with open(\"G_train_dgl.gpickle\", \"rb\") as f:\n",
    "    G_train_dgl = pickle.load(f)\n",
    "    \n",
    "with open(\"G_val_dgl.gpickle\", \"rb\") as f:\n",
    "    G_val_dgl = pickle.load(f)\n",
    "    \n",
    "with open(\"G_test_dgl.gpickle\", \"rb\") as f:\n",
    "    G_test_dgl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 10 nodes in G_train_dgl, G_val_dgl, G_test_dgl\n",
    "print({i: G_train_dgl.ndata['features'][i] for i in range(10)})\n",
    "print({i: G_val_dgl.ndata['features'][i] for i in range(10)})\n",
    "print({i: G_test_dgl.ndata['features'][i] for i in range(10)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "import copy\n",
    "import random\n",
    "# Set the random seed, a randamly selected number\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, out_feats, dropout_rate):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size)\n",
    "        self.conv2 = GraphConv(hidden_size, hidden_size)  # added layer\n",
    "        self.conv3 = GraphConv(hidden_size, out_feats)  # final layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # dropout layer\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden_size)  # batchnorm layer\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = F.relu(self.conv1(g, features))\n",
    "        x = self.dropout(x)  # apply dropout\n",
    "        x = self.batchnorm1(x)  # apply batchnorm\n",
    "        x = F.relu(self.conv2(g, x))\n",
    "        x = self.dropout(x)  # apply dropout\n",
    "        # x = self.batchnorm1(x)  # apply batchnorm\n",
    "        x = self.conv3(g, x)\n",
    "        return x\n",
    "\n",
    "# Get the number of input features\n",
    "in_feats = G_train_dgl.ndata['normalized_features'].shape[1]\n",
    "\n",
    "# Define the model hyperparameters\n",
    "hidden_size = 128\n",
    "out_feats = 2  # Assuming binary classification\n",
    "dropout_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # Set the random seed, a randamly selected number\n",
    "    seed = random.randint(0, 1000)\n",
    "    print(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # Create the GCN model\n",
    "    model = GCN(in_feats, hidden_size, out_feats, dropout_rate)\n",
    "\n",
    "    # Define the optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    num_epochs = 200\n",
    "    patience = 20\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        labels = G_train_dgl.ndata['label'].squeeze()\n",
    "        features = G_train_dgl.ndata['normalized_features']\n",
    "\n",
    "        # Select indices of 0 and 1 labels\n",
    "        zero_indices = torch.where(labels == 0)[0]\n",
    "        one_indices = torch.where(labels == 1)[0]\n",
    "        \n",
    "        # Get the minimum count between 0 and 1 labels\n",
    "        min_count = min(zero_indices.shape[0], one_indices.shape[0])\n",
    "        \n",
    "        # Randomly select 'min_count' indices from zero_indices and one_indices each\n",
    "        selected_zero_indices = zero_indices[torch.randperm(zero_indices.shape[0])[:min_count]]\n",
    "        selected_one_indices = one_indices[torch.randperm(one_indices.shape[0])[:min_count]]\n",
    "\n",
    "        # Combine the selected indices\n",
    "        selected_indices = torch.cat((selected_zero_indices, selected_one_indices))\n",
    "\n",
    "        # Shuffle the selected indices\n",
    "        selected_indices = selected_indices[torch.randperm(selected_indices.shape[0])]\n",
    "\n",
    "        # Create a subgraph from the selected indices\n",
    "        subgraph = dgl.node_subgraph(G_train_dgl, selected_indices)\n",
    "\n",
    "        # Get the selected features and labels\n",
    "        selected_features = subgraph.ndata['normalized_features']\n",
    "        selected_labels = subgraph.ndata['label'].squeeze()\n",
    "\n",
    "        # Forward pass and compute the loss\n",
    "        logits = model(subgraph, selected_features)\n",
    "        labels = F.one_hot(selected_labels, num_classes=out_feats).float()\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Create balanced validation set\n",
    "            labels = G_val_dgl.ndata['label'].squeeze()\n",
    "\n",
    "            # Select indices of 0 and 1 labels\n",
    "            zero_indices = torch.where(labels == 0)[0]\n",
    "            one_indices = torch.where(labels == 1)[0]\n",
    "\n",
    "            # Get the minimum count between 0 and 1 labels\n",
    "            min_count = min(zero_indices.shape[0], one_indices.shape[0])\n",
    "\n",
    "            # Randomly select 'min_count' indices from zero_indices and one_indices each\n",
    "            selected_zero_indices = zero_indices[torch.randperm(zero_indices.shape[0])[:min_count]]\n",
    "            selected_one_indices = one_indices[torch.randperm(one_indices.shape[0])[:min_count]]\n",
    "\n",
    "            # Combine the selected indices\n",
    "            selected_indices = torch.cat((selected_zero_indices, selected_one_indices))\n",
    "\n",
    "            # Shuffle the selected indices\n",
    "            selected_indices = selected_indices[torch.randperm(selected_indices.shape[0])]\n",
    "\n",
    "            # Create a subgraph from the selected indices\n",
    "            subgraph = dgl.node_subgraph(G_val_dgl, selected_indices)\n",
    "\n",
    "            # Get the selected features and labels\n",
    "            selected_features = subgraph.ndata['normalized_features']\n",
    "            selected_labels = subgraph.ndata['label'].squeeze()\n",
    "\n",
    "            # Validation\n",
    "            logits = model(subgraph, selected_features)\n",
    "            labels = F.one_hot(selected_labels, num_classes=out_feats).float()\n",
    "            val_loss = criterion(logits, labels)\n",
    "            \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(f\"Epoch: {epoch + 1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Create balanced testing set\n",
    "        labels = G_test_dgl.ndata['label'].squeeze()\n",
    "\n",
    "        # Select indices of 0 and 1 labels\n",
    "        zero_indices = torch.where(labels == 0)[0]\n",
    "        one_indices = torch.where(labels == 1)[0]\n",
    "\n",
    "        # Get the minimum count between 0 and 1 labels\n",
    "        min_count = min(zero_indices.shape[0], one_indices.shape[0])\n",
    "\n",
    "        # Randomly select 'min_count' indices from zero_indices and one_indices each\n",
    "        selected_zero_indices = zero_indices[torch.randperm(zero_indices.shape[0])[:min_count]]\n",
    "        selected_one_indices = one_indices[torch.randperm(one_indices.shape[0])[:min_count]]\n",
    "\n",
    "        # Combine the selected indices\n",
    "        selected_indices = torch.cat((selected_zero_indices, selected_one_indices))\n",
    "\n",
    "        # Shuffle the selected indices\n",
    "        selected_indices = selected_indices[torch.randperm(selected_indices.shape[0])]\n",
    "\n",
    "        # Create a subgraph from the selected indices\n",
    "        subgraph = dgl.node_subgraph(G_test_dgl, selected_indices)\n",
    "\n",
    "        # Get the selected features and labels\n",
    "        selected_features = subgraph.ndata['normalized_features']\n",
    "        ground_truth = subgraph.ndata['label'].squeeze()\n",
    "\n",
    "        # Testing\n",
    "        logits = best_model(subgraph, selected_features)\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "        # Calculate additional evaluation metrics for testing\n",
    "        predicted_probs = F.softmax(logits, dim=1)[:, 1]\n",
    "        predicted_labels = (predicted_probs > 0.5).float()\n",
    "        auc = roc_auc_score(ground_truth.detach().numpy(), predicted_probs.detach().numpy())\n",
    "        f1 = f1_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy())\n",
    "        precision = precision_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy())\n",
    "        recall = recall_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy())\n",
    "        accuracy = accuracy_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy())\n",
    "        macro_f1 = f1_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy(), average='macro')\n",
    "        macro_precision = precision_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy(), average='macro')\n",
    "        macro_recall = recall_score(ground_truth.detach().numpy(), predicted_labels.detach().numpy(), average='macro')\n",
    "        # store results in a txt file\n",
    "        with open(\"GCN_wo_results.txt\", \"a\") as f:\n",
    "            # need to write random seed, validation loss, test loss, auc, f1, precision, recall\n",
    "            f.write(f\"Random seed: {seed}, Epoch: {epoch + 1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}, AUC: {auc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, Macro-F1: {macro_f1:.4f}, Macro-Precision: {macro_precision:.4f}, Macro-recall: {macro_recall:.4f}\\n\")\n",
    "        print(f\"AUC: {auc:.4f}, F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, Macro-F1: {macro_f1:.4f}, Macro-Precision: {macro_precision:.4f}, Macro-recall: {macro_recall:.4f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
